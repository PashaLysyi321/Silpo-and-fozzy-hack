{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "identical-division",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import re\n",
    "import html2text\n",
    "import requests\n",
    "from google_trans_new import google_translator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import io\n",
    "from urllib.request import urlopen\n",
    "from datetime import datetime\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "educational-carry",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "def get_component(comp_name):\n",
    "    url = f'https://dobavkam.net/additives/{comp_name.lower()}'\n",
    "    while True:\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            break\n",
    "        except:\n",
    "            continue\n",
    "    soup = BeautifulSoup(response.text, 'lxml')\n",
    "    for i in range(1,7):\n",
    "        try:\n",
    "            a = soup.find('a', class_=f'addprop-item addprop-item--danger-{i}').text\n",
    "            try:\n",
    "                info = soup.find('div', class_='field field--block field--additive-info')\n",
    "                info = info.find('p').text.replace('\\xa0',' ')\n",
    "                if i>=2:\n",
    "                    return 0, info\n",
    "                else:\n",
    "                    return 1, info\n",
    "                return i, info\n",
    "            except:\n",
    "                return i, -1\n",
    "        except:\n",
    "            pass\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "elementary-supervision",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html_tags(text):\n",
    "    \"\"\"Remove html tags from a string\"\"\"\n",
    "    clean = re.compile('<.*?>|&ndash; ')\n",
    "    return re.sub(clean, '', text)\n",
    "\n",
    "def remove_html_tags2(text):\n",
    "    h = html2text.HTML2Text()\n",
    "    h.ignore_links = True\n",
    "    text1 = h.handle(text)\n",
    "    text2 = remove_html_tags(text1).replace('\\n',' ').replace(\"/\",' ').replace(\"*\",' ').replace(\"[]\",' ').replace('_',' ')\n",
    "    text2 = re.sub(r'\\([^)]*\\)', '', text2).replace('\\\\',' ').replace('#',' ').replace('>',' ').replace('  ',' ').replace('  ',' ').replace('  ',' ')\n",
    "    if text1 != 'None':\n",
    "        return text2\n",
    "    else:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "economic-beatles",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def parsing_wiki(query):\n",
    "\n",
    "    URL = \"https://ru.wikipedia.org/wiki/\"+str(query)\n",
    "    page = requests.get(URL)\n",
    "\n",
    "    text = str(page.text).split('<p>')[1]\n",
    "    text = remove_html_tags2(remove_html_tags(text))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "published-kansas",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rating(text):\n",
    "    neg = []\n",
    "    pos = []\n",
    "    for sentence in text.split('.'):\n",
    "        sid = SentimentIntensityAnalyzer()\n",
    "        ss = sid.polarity_scores(sentence)\n",
    "        data14 = 'neg:' + str(ss['neg']) + '  pos:' + str(ss['pos'])\n",
    "        neg.append(float(ss['neg']))\n",
    "        pos.append(float(ss['pos']))\n",
    "\n",
    "    try:\n",
    "        pos = sum(pos)\n",
    "        neg = sum(neg)\n",
    "        summ = pos+neg\n",
    "        pos /=summ\n",
    "        neg /=summ\n",
    "        if pos>0.7:\n",
    "            res = 1\n",
    "        else:\n",
    "            res = 0\n",
    "        return res\n",
    "    except: \n",
    "        return 1\n",
    "def get_text_from_wiki(query):\n",
    "    translator = google_translator()\n",
    "    return translator.translate(parsing_wiki(query), lang_src='ru',lang_tgt='en')\n",
    "    return parsing_wiki(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "interior-alexandria",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(query):\n",
    "    rating = get_component(query)\n",
    "    if  rating == -1:\n",
    "        rating = get_rating(get_text_from_wiki(query))\n",
    "        text = get_text_from_wiki(query)\n",
    "        text = re.sub(r'\\[[^\\]]+\\]', '', text)\n",
    "        if text == 'У Википедии нет статьи с таким именем. ':\n",
    "            rating = 1\n",
    "        return rating,text\n",
    "    return rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cognitive-liquid",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html_tags(text):\n",
    "    \"\"\"Remove html tags from a string\"\"\"\n",
    "    clean = re.compile('<.*?>|&ndash; ')\n",
    "    return re.sub(clean, '', text)\n",
    "\n",
    "def replase_to_bool(val):\n",
    "    if val == 'НЕТ':\n",
    "        ans = False\n",
    "    elif val == 'ДА':\n",
    "        ans = True\n",
    "    return ans\n",
    "\n",
    "    \n",
    "def scraping_product(id):\n",
    "    qr_id = id\n",
    "\n",
    "    qr_url = f'https://listex.info/search/?q={qr_id}&type=goods'\n",
    "\n",
    "    #qr_html_text=requests.get(qr_url, headers = {'User-agent': 'your bot 0.1'}).text\n",
    "    qr_html_text = requests.get(qr_url).text\n",
    "    qr_soup = BeautifulSoup(qr_html_text, 'lxml')\n",
    "    for link in qr_soup.find_all('a', class_='link-gray'):\n",
    "        href = re.match(r'.product.', link.get('href'))\n",
    "        if href:\n",
    "            prod_link = 'https://listex.info/' + link.get('href')\n",
    "\n",
    "    prod_html_text = requests.get(prod_link).text\n",
    "    prod_soup = BeautifulSoup(prod_html_text, 'lxml')\n",
    "\n",
    "    try:\n",
    "        list_text = prod_soup.find('p', class_=\"product-specifications-title\").get_text().split()[1:]\n",
    "        prod_name = ' '.join(list_text)\n",
    "    except:\n",
    "        prod_name = 0\n",
    "        \n",
    "    try:        \n",
    "        log_params = str(prod_soup).split('Материал транспортной тары')[1].split('<div')[0]\n",
    "        package = log_params.split('Материал транспортной тары')[1].replace('</th>','').replace('\\n','').replace('<tr>','').replace('<th>','').replace('<td>','').replace('</td>','').replace('</tr>','').split('Белки, г/100г')[0].replace(' ','').replace('\\t', '').replace('</table>','')\n",
    "    except:\n",
    "        package = 0\n",
    "        \n",
    "    try:\n",
    "        log_params2 = str(prod_soup).split('Вес нетто, пустой box, кг')[1].split('<div')[0]\n",
    "        mass = log_params2.split('Вес нетто, пустой box, кг')[1].replace('</th>','').replace('\\n','').replace('<tr>','').replace('<th>','').replace('<td>','').replace('</td>','').replace('</tr>','').split('Белки, г/100г')[0].replace(' ','').replace('\\t', '').replace('</table>','')\n",
    "    except:\n",
    "        mass = 0\n",
    "\n",
    "    try:\n",
    "        nutritional = str(prod_soup).split('Питательные характеристики')[1].split('<div')[0]\n",
    "        clean_text = remove_html_tags(remove_html_tags(nutritional)).replace('\\n','').replace('\\t','')\n",
    "        clean_text = clean_text.split('  ')\n",
    "\n",
    "        ans = []\n",
    "        for i in clean_text:\n",
    "            if len(i) !=0:\n",
    "                ans.append(i)\n",
    "                pass\n",
    "    \n",
    "        if 'Жиры, г/100г' in ans:\n",
    "            fats = ans[ans.index('Жиры, г/100г')+1].replace('&lt;','')\n",
    "        elif 'Жиры, г/100мл' in ans:\n",
    "            fats = ans[ans.index('Жиры, г/100мл')+1].replace('&lt;','')\n",
    "        else:\n",
    "            fats = 'НЕТ'\n",
    "            \n",
    "        if 'Углеводы, г/100г' in ans:\n",
    "            carbohydrates = ans[ans.index('Углеводы, г/100г')+1].replace('&lt;','')\n",
    "        elif 'Углеводы, г/100мл' in ans:\n",
    "            carbohydrates = ans[ans.index('Углеводы, г/100мл')+1].replace('&lt;','')\n",
    "        else:\n",
    "            carbohydrates = 'НЕТ'\n",
    "            \n",
    "        if 'Белки, г/100г' in ans:\n",
    "            proteins = ans[ans.index('Белки, г/100г')+1].replace('&lt;','')\n",
    "        elif 'Белки, г/100мл' in ans:\n",
    "            proteins = ans[ans.index('Белки, г/100мл')+1].replace('&lt;','')\n",
    "        else:\n",
    "            proteins = 'НЕТ'\n",
    "            \n",
    "        if 'Калорийность, ккал/100г' in ans:\n",
    "            calories = ans[ans.index('Калорийность, ккал/100г')+1].replace('&lt;','')\n",
    "        elif 'Калорийность, ккал/100мл' in ans:\n",
    "            calories = ans[ans.index('Калорийность, ккал/100мл')+1].replace('&lt;','')\n",
    "        else:\n",
    "            calories = 'НЕТ'\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        fats=0\n",
    "        proteins=0\n",
    "        calories=0\n",
    "        carbohydrates=0\n",
    "        kdg=0\n",
    "        \n",
    "    try:\n",
    "        main = str(prod_soup).split('Основные')[1].split('<div')[0]\n",
    "        clean_text = remove_html_tags(main).replace('\\n','').replace('\\t','')\n",
    "        clean_text = clean_text.split('  ')\n",
    "\n",
    "        ans = []\n",
    "        for i in clean_text:\n",
    "            if len(i) !=0:\n",
    "                ans.append(i)\n",
    "                pass\n",
    "        if 'Органический продукт' in ans:\n",
    "            organic = ans[ans.index('Органический продукт')+1]     \n",
    "        else:\n",
    "            organic = 'НЕТ'\n",
    "        if 'ГМО' in ans:\n",
    "            gmo = ans[ans.index('ГМО')+1]    \n",
    "        else:\n",
    "            gmo = 'НЕТ'\n",
    "        if 'Подходит вегетарианцам' in ans:\n",
    "            vegetarian = ans[ans.index('Подходит вегетарианцам')+1]     \n",
    "        else:\n",
    "            vegetarian = 'НЕТ'\n",
    "        if 'Подходит веганам' in ans:\n",
    "            vegan = ans[ans.index('Подходит веганам')+1]     \n",
    "        else:\n",
    "            vegan = 'НЕТ'\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        gmo = 0\n",
    "        organic = 0\n",
    "        vegetarian = 0\n",
    "        vegan = 0\n",
    "\n",
    "    try:       \n",
    "        description = str(prod_soup).split('Состав товара')[1].split('<div')[0]\n",
    "        components = remove_html_tags(description).replace('\\n','').replace('\\t','').split('Состав (рус.)')[1].split('Состав (укр.)')[0].replace('  ','')\n",
    "    except:\n",
    "        components = 0\n",
    "        \n",
    "    try:\n",
    "        package1 = str(prod_soup).replace('\\n','').replace('\\t','').split('Упаковка    ')[1].split('<div')[0]\n",
    "        ans1 = []\n",
    "        for i in remove_html_tags(package1).replace('\\n','').replace('\\t','').split('   '):\n",
    "            if len(i) !=0:\n",
    "                ans1.append(i)    \n",
    "    except:\n",
    "        ans1 = [0,0,0,0] \n",
    "    \n",
    "    page = requests.get(prod_link)\n",
    "    soup = BeautifulSoup(page.text)\n",
    "    images = soup.findAll('img')\n",
    "    for image in images:\n",
    "        if re.findall(r'https://', image['src']):\n",
    "            img = image['src']\n",
    "            break\n",
    "\n",
    "    dict_ = {\n",
    "        'barcode': qr_id,\n",
    "        'name': prod_name,\n",
    "        'proteins': proteins, \n",
    "        'fats': fats,\n",
    "        'carbohydrates': carbohydrates,\n",
    "        'calories': calories,\n",
    "        'mass': float(mass),\n",
    "        'package': package,\n",
    "        'package2':ans1,\n",
    "        'is_gmo': gmo,\n",
    "        'is_organic': organic,\n",
    "        'is_vegetarian': vegetarian,\n",
    "        'is_vegan': vegan,\n",
    "        'components': components,\n",
    "        #'img':img\n",
    "    }\n",
    "    return dict_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "exact-scanning",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list index out of range\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'barcode': 4820051240233,\n",
       " 'name': 'Вода минеральная негазированная Карпатська Джерельна п/бут 0.5л.',\n",
       " 'proteins': 0,\n",
       " 'fats': 0,\n",
       " 'carbohydrates': 0,\n",
       " 'calories': 0,\n",
       " 'mass': 0.0,\n",
       " 'package': 0,\n",
       " 'package2': ['  Материал упаковки',\n",
       "  'ПОЛИЭТИЛЕНТЕРЕФТАЛАТ (ПЭТ/ПЭТФ)',\n",
       "  ' Тип упаковки',\n",
       "  'БУТЫЛКА {BOT}'],\n",
       " 'is_gmo': 'НЕТ',\n",
       " 'is_organic': 'НЕТ',\n",
       " 'is_vegetarian': 'ДА',\n",
       " 'is_vegan': 'ДА',\n",
       " 'components': 'Вода минеральная'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json = scraping_product(4820051240233)\n",
    "json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "owned-kuwait",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Вода минеральная']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "s = json.get('components')\n",
    "mass = s.split(',')\n",
    "mass1 = []\n",
    "check_mass = []\n",
    "\n",
    "for jj in re.findall(r'(?:[^\\d]|\\A)(\\d{3})(?:[^\\d]|\\Z)', s):\n",
    "    mass1.append('E'+jj)\n",
    "    check_mass.append('Е'+jj)\n",
    "    \n",
    "for i in mass:\n",
    "    try:\n",
    "        checker = 0\n",
    "        for ji in check_mass:\n",
    "            if ji in i:\n",
    "                checker = 1\n",
    "        if checker == 0:\n",
    "            mass1.append(i.replace('(','').replace(')','').replace('\"','').replace(\"'\",''))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "print(mass1)\n",
    "\n",
    "component_vs_rating = []\n",
    "\n",
    "for j in mass1:\n",
    "    component_vs_rating.append(main(j))\n",
    "\n",
    "plus = sum([i[0] for i in component_vs_rating])/len(component_vs_rating)\n",
    "json[\"Positive\"] = round(plus,2)\n",
    "json[\"Negative\"] = 1-plus\n",
    "json[\"Componenets_vs_rating\"] = component_vs_rating "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "classified-lancaster",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'barcode': 4820051240233,\n",
       " 'name': 'Вода минеральная негазированная Карпатська Джерельна п/бут 0.5л.',\n",
       " 'proteins': 0,\n",
       " 'fats': 0,\n",
       " 'carbohydrates': 0,\n",
       " 'calories': 0,\n",
       " 'mass': 0.0,\n",
       " 'package': 0,\n",
       " 'package2': ['  Материал упаковки',\n",
       "  'ПОЛИЭТИЛЕНТЕРЕФТАЛАТ (ПЭТ/ПЭТФ)',\n",
       "  ' Тип упаковки',\n",
       "  'БУТЫЛКА {BOT}'],\n",
       " 'is_gmo': 'НЕТ',\n",
       " 'is_organic': 'НЕТ',\n",
       " 'is_vegetarian': 'ДА',\n",
       " 'is_vegan': 'ДА',\n",
       " 'components': 'Вода минеральная',\n",
       " 'Positive': 0.0,\n",
       " 'Negative': 1.0,\n",
       " 'Componenets_vs_rating': [(0, 'Wikipedia has no article with such a name. ')]}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
