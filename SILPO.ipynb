{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.7"
    },
    "colab": {
      "name": "SILPO(2).ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hzj_XgUSiGgg"
      },
      "source": [
        "# !pip install html2text\n",
        "# !pip install google_trans_new"
      ],
      "id": "Hzj_XgUSiGgg",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "different-founder"
      },
      "source": [
        "import nltk\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "import re\n",
        "import html2text\n",
        "import requests\n",
        "from google_trans_new import google_translator\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import io\n",
        "from urllib.request import urlopen\n",
        "from datetime import datetime\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.request import urlopen"
      ],
      "id": "different-founder",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zWxYnoc_W07",
        "outputId": "ffb5a57d-300c-45fb-8af5-372d47de67d4"
      },
      "source": [
        "import nltk\n",
        "nltk.download('vader_lexicon')"
      ],
      "id": "9zWxYnoc_W07",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "painful-retirement"
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "\n",
        "def get_component(comp_name):\n",
        "    url = f'https://dobavkam.net/additives/{comp_name.lower()}'\n",
        "    while True:\n",
        "        try:\n",
        "            response = requests.get(url)\n",
        "            break\n",
        "        except:\n",
        "            continue\n",
        "    soup = BeautifulSoup(response.text, 'lxml')\n",
        "    for i in range(1,7):\n",
        "        try:\n",
        "            a = soup.find('a', class_=f'addprop-item addprop-item--danger-{i}').text\n",
        "            try:\n",
        "                info = soup.find('div', class_='field field--block field--additive-info')\n",
        "                info = info.find('p').text.replace('\\xa0',' ')\n",
        "                if i>=2:\n",
        "                    return 0, info\n",
        "                else:\n",
        "                    return 1, info\n",
        "                return i, info\n",
        "            except:\n",
        "                return i, -1\n",
        "        except:\n",
        "            pass\n",
        "    return -1"
      ],
      "id": "painful-retirement",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taken-trading"
      },
      "source": [
        "def remove_html_tags(text):\n",
        "    \"\"\"Remove html tags from a string\"\"\"\n",
        "    clean = re.compile('<.*?>|&ndash; ')\n",
        "    return re.sub(clean, '', text)\n",
        "\n",
        "def remove_html_tags2(text):\n",
        "    h = html2text.HTML2Text()\n",
        "    h.ignore_links = True\n",
        "    text1 = h.handle(text)\n",
        "    text2 = remove_html_tags(text1).replace('\\n',' ').replace(\"/\",' ').replace(\"*\",' ').replace(\"[]\",' ').replace('_',' ')\n",
        "    text2 = re.sub(r'\\([^)]*\\)', '', text2).replace('\\\\',' ').replace('#',' ').replace('>',' ').replace('  ',' ').replace('  ',' ').replace('  ',' ')\n",
        "    if text1 != 'None':\n",
        "        return text2\n",
        "    else:\n",
        "        return text"
      ],
      "id": "taken-trading",
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "convenient-reminder"
      },
      "source": [
        "def parsing_wiki(query):\n",
        "\n",
        "    URL = \"https://ru.wikipedia.org/wiki/\"+str(query)\n",
        "    page = requests.get(URL)\n",
        "\n",
        "    text = str(page.text).split('<p>')[1]\n",
        "    text = remove_html_tags2(remove_html_tags(text))\n",
        "    return text"
      ],
      "id": "convenient-reminder",
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dental-prayer"
      },
      "source": [
        "def get_rating(text):\n",
        "    neg = []\n",
        "    pos = []\n",
        "    for sentence in text.split('.'):\n",
        "        sid = SentimentIntensityAnalyzer()\n",
        "        ss = sid.polarity_scores(sentence)\n",
        "        data14 = 'neg:' + str(ss['neg']) + '  pos:' + str(ss['pos'])\n",
        "        neg.append(float(ss['neg']))\n",
        "        pos.append(float(ss['pos']))\n",
        "\n",
        "    try:\n",
        "        pos = sum(pos)\n",
        "        neg = sum(neg)\n",
        "        summ = pos+neg\n",
        "        pos /=summ\n",
        "        neg /=summ\n",
        "        if pos>0.7:\n",
        "            res = 1\n",
        "        else:\n",
        "            res = 0\n",
        "        return res\n",
        "    except: \n",
        "        return 1\n",
        "def get_text_from_wiki(query):\n",
        "    translator = google_translator()\n",
        "    #return translator.translate(parsing_wiki(query), lang_src='ru',lang_tgt='en')\n",
        "    return parsing_wiki(query)"
      ],
      "id": "dental-prayer",
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "actual-harris"
      },
      "source": [
        ""
      ],
      "id": "actual-harris",
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "preliminary-street"
      },
      "source": [
        "def remove_html_tags(text):\n",
        "    \"\"\"Remove html tags from a string\"\"\"\n",
        "    clean = re.compile('<.*?>|&ndash; ')\n",
        "    return re.sub(clean, '', text)\n",
        "\n",
        "def replase_to_bool(val):\n",
        "    if val == 'НЕТ':\n",
        "        ans = False\n",
        "    elif val == 'ДА':\n",
        "        ans = True\n",
        "    return ans\n",
        "\n",
        "    \n",
        "def scraping_product(id):\n",
        "    qr_id = id\n",
        "\n",
        "    qr_url = f'https://listex.info/search/?q={qr_id}&type=goods'\n",
        "    #qr_html_text=requests.get(qr_url, headers = {'User-agent': 'your bot 0.1'}).text\n",
        "    qr_html_text = requests.get(qr_url).text\n",
        "    qr_soup = BeautifulSoup(qr_html_text, 'lxml')\n",
        "    for link in qr_soup.find_all('a', class_='link-gray'):\n",
        "        href = re.match(r'.product.', link.get('href'))\n",
        "        if href:\n",
        "            prod_link = 'https://listex.info/' + link.get('href')\n",
        "\n",
        "    prod_html_text = requests.get(prod_link).text\n",
        "    prod_soup = BeautifulSoup(prod_html_text, 'lxml')\n",
        "\n",
        "    try:\n",
        "        list_text = prod_soup.find('p', class_=\"product-specifications-title\").get_text().split()[1:]\n",
        "        prod_name = ' '.join(list_text)\n",
        "    except:\n",
        "        prod_name = 0\n",
        "        \n",
        "    try:        \n",
        "        log_params = str(prod_soup).split('Материал транспортной тары')[1].split('<div')[0]\n",
        "        package = log_params.split('Материал транспортной тары')[1].replace('</th>','').replace('\\n','').replace('<tr>','').replace('<th>','').replace('<td>','').replace('</td>','').replace('</tr>','').split('Белки, г/100г')[0].replace(' ','').replace('\\t', '').replace('</table>','')\n",
        "    except:\n",
        "        package = 0\n",
        "        \n",
        "    try:\n",
        "        log_params2 = str(prod_soup).split('Вес нетто, пустой box, кг')[1].split('<div')[0]\n",
        "        mass = log_params2.split('Вес нетто, пустой box, кг')[1].replace('</th>','').replace('\\n','').replace('<tr>','').replace('<th>','').replace('<td>','').replace('</td>','').replace('</tr>','').split('Белки, г/100г')[0].replace(' ','').replace('\\t', '').replace('</table>','')\n",
        "    except:\n",
        "        mass = 0\n",
        "\n",
        "    try:\n",
        "        nutritional = str(prod_soup).split('Питательные характеристики')[1].split('<div')[0]\n",
        "        clean_text = remove_html_tags(remove_html_tags(nutritional)).replace('\\n','').replace('\\t','')\n",
        "        clean_text = clean_text.split('  ')\n",
        "\n",
        "        ans = []\n",
        "        for i in clean_text:\n",
        "            if len(i) !=0:\n",
        "                ans.append(i)\n",
        "                pass\n",
        "    \n",
        "        if 'Жиры, г/100г' in ans:\n",
        "            fats = ans[ans.index('Жиры, г/100г')+1].replace('&lt;','')\n",
        "        elif 'Жиры, г/100мл' in ans:\n",
        "            fats = ans[ans.index('Жиры, г/100мл')+1].replace('&lt;','')\n",
        "        else:\n",
        "            fats = 'НЕТ'\n",
        "            \n",
        "        if 'Углеводы, г/100г' in ans:\n",
        "            carbohydrates = ans[ans.index('Углеводы, г/100г')+1].replace('&lt;','')\n",
        "        elif 'Углеводы, г/100мл' in ans:\n",
        "            carbohydrates = ans[ans.index('Углеводы, г/100мл')+1].replace('&lt;','')\n",
        "        else:\n",
        "            carbohydrates = 'НЕТ'\n",
        "            \n",
        "        if 'Белки, г/100г' in ans:\n",
        "            proteins = ans[ans.index('Белки, г/100г')+1].replace('&lt;','')\n",
        "        elif 'Белки, г/100мл' in ans:\n",
        "            proteins = ans[ans.index('Белки, г/100мл')+1].replace('&lt;','')\n",
        "        else:\n",
        "            proteins = 'НЕТ'\n",
        "            \n",
        "        if 'Калорийность, ккал/100г' in ans:\n",
        "            calories = ans[ans.index('Калорийность, ккал/100г')+1].replace('&lt;','')\n",
        "        elif 'Калорийность, ккал/100мл' in ans:\n",
        "            calories = ans[ans.index('Калорийность, ккал/100мл')+1].replace('&lt;','')\n",
        "        else:\n",
        "            calories = 'НЕТ'\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        fats=0\n",
        "        proteins=0\n",
        "        calories=0\n",
        "        carbohydrates=0\n",
        "        kdg=0\n",
        "        \n",
        "    try:\n",
        "        main = str(prod_soup).split('Основные')[1].split('<div')[0]\n",
        "        clean_text = remove_html_tags(main).replace('\\n','').replace('\\t','')\n",
        "        clean_text = clean_text.split('  ')\n",
        "\n",
        "        ans = []\n",
        "        for i in clean_text:\n",
        "            if len(i) !=0:\n",
        "                ans.append(i)\n",
        "                pass\n",
        "        if 'Органический продукт' in ans:\n",
        "            organic = ans[ans.index('Органический продукт')+1]     \n",
        "        else:\n",
        "            organic = 'НЕТ'\n",
        "        if 'ГМО' in ans:\n",
        "            gmo = ans[ans.index('ГМО')+1]    \n",
        "        else:\n",
        "            gmo = 'НЕТ'\n",
        "        if 'Подходит вегетарианцам' in ans:\n",
        "            vegetarian = ans[ans.index('Подходит вегетарианцам')+1]     \n",
        "        else:\n",
        "            vegetarian = 'НЕТ'\n",
        "        if 'Подходит веганам' in ans:\n",
        "            vegan = ans[ans.index('Подходит веганам')+1]     \n",
        "        else:\n",
        "            vegan = 'НЕТ'\n",
        "    \n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        gmo = 0\n",
        "        organic = 0\n",
        "        vegetarian = 0\n",
        "        vegan = 0\n",
        "\n",
        "    try:       \n",
        "        description = str(prod_soup).split('Состав товара')[1].split('<div')[0]\n",
        "        components = remove_html_tags(description).replace('\\n','').replace('\\t','').split('Состав (рус.)')[1].split('Состав (укр.)')[0].replace('  ','')\n",
        "    except:\n",
        "        components = 0\n",
        "        \n",
        "    try:\n",
        "        package1 = str(prod_soup).replace('\\n','').replace('\\t','').split('Упаковка    ')[1].split('<div')[0]\n",
        "        ans1 = []\n",
        "        for i in remove_html_tags(package1).replace('\\n','').replace('\\t','').split('   '):\n",
        "            if len(i) !=0:\n",
        "                ans1.append(i)    \n",
        "    except:\n",
        "        ans1 = [0,0,0,0] \n",
        "    \n",
        "    page = urlopen(prod_link)\n",
        "    soup = BeautifulSoup(page)\n",
        "    images = soup.findAll('img')\n",
        "    for image in images:\n",
        "        if re.findall(r'https://', image['src']):\n",
        "            img = image['src']\n",
        "            break\n",
        "\n",
        "    dict_ = {\n",
        "        'barcode': qr_id,\n",
        "        'name': prod_name,\n",
        "        'proteins': proteins, \n",
        "        'fats': fats,\n",
        "        'carbohydrates': carbohydrates,\n",
        "        'calories': calories,\n",
        "        'mass': float(mass),\n",
        "        'package': package,\n",
        "        'package2':ans1[1]+', '+ans1[3],\n",
        "        'is_gmo': gmo,\n",
        "        'is_organic': organic,\n",
        "        'is_vegetarian': vegetarian,\n",
        "        'is_vegan': vegan,\n",
        "        'components': components,\n",
        "        'img':img\n",
        "    }\n",
        "    return dict_"
      ],
      "id": "preliminary-street",
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "artistic-handbook"
      },
      "source": [
        "import re\n",
        "\n",
        "def runn(id):\n",
        "    json = scraping_product(id)\n",
        "    def main(query):\n",
        "        try:\n",
        "            rating = get_component(query)\n",
        "            if  rating == -1:\n",
        "                rating = get_rating(get_text_from_wiki(query))\n",
        "                #text = translator.translate(get_text_from_wiki(query), lang_src='en',lang_tgt='ru')\n",
        "                text = get_text_from_wiki(query)\n",
        "                text = re.sub(r'\\[[^\\]]+\\]', '', text)\n",
        "                if text == 'У Википедии нет статьи с таким именем. ':\n",
        "                    rating = 1\n",
        "                return rating,text\n",
        "            return rating\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "            return 1, ''\n",
        "    s = json.get('components')\n",
        "    mass = s.split(',')\n",
        "    mass1 = []\n",
        "    check_mass = []\n",
        "\n",
        "    for jj in re.findall(r'(?:[^\\d]|\\A)(\\d{3})(?:[^\\d]|\\Z)', s):\n",
        "        mass1.append('E'+jj)\n",
        "        check_mass.append('Е'+jj)\n",
        "        \n",
        "    for i in mass:\n",
        "        try:\n",
        "            checker = 0\n",
        "            for ji in check_mass:\n",
        "                if ji in i:\n",
        "                    checker = 1\n",
        "            if checker == 0:\n",
        "                tt = i.replace('(','').replace(')','').replace('\"','').replace(\"'\",'')\n",
        "                if tt[0] ==' ':\n",
        "                    tt = tt[1:]\n",
        "                mass1.append(tt)\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "\n",
        "\n",
        "    component_vs_rating = []\n",
        "\n",
        "    for j in mass1:\n",
        "        try:\n",
        "            component_vs_rating.append(main(j))\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "            print(main(j))\n",
        "\n",
        "    plus = sum([i[0] for i in component_vs_rating])/len(component_vs_rating)\n",
        "    json[\"components\"] = str(mass1).replace('[','').replace(']','').replace(\"'\",'')\n",
        "    json[\"Positive\"] = round(plus,2)\n",
        "    json[\"Negative\"] = round(1-plus,2)\n",
        "    json[\"Componenets_vs_rating\"] = component_vs_rating\n",
        "\n",
        "    garbage_disposal = {\"Стекло\": \"Выбрасываем: бутылки, банки, стеклобой (битый тара) от напитков, лекарственных средств и т.п., битое оконное стекло. Не выбрасываем: зеркала, хрусталь, армированное стекло, фарфор, жаро- и ударопрочное стекло, любые лампочки.\",\n",
        "                    \"Бумага\": \"Выбрасываем: белую бумагу, картон, бумажные упаковки, пакеты из бумаги, книги, открытки, газеты, журналы, тетради, альбомы. Не выбрасываем: смешанную упаковку (tetra pak, pure pak), магазинные чеки, транспортные квитанции, бумагу ламинированную или с самоклеющейся поверхностью, изделия, которые уже проходили переработку ранее (например, лотки от яиц), хозяйственный бумагу, коробки от сигарет, загрязненную или влажную бумагу.\",\n",
        "                    \"Пластик\": \"Выбрасываем: тару и упаковку – если видите на упаковке цифру 1 или маркировки PET, PETE; полиэтилен высокой и низкой плотности – маркировка HDPE, LDPE, или цифры 2 или 4; полипропилен в виде пленки, флаконов или контейнеров, полиэтилен в виде пленки – маркировка РР, или цифра 5, полистирена, полистирол – маркировка 6; упаковка tetra pak и pure pak. Не выбрасываем: цветные непрозрачные бутылки РЕТ черного, белого и желтого цветов; поливинилхлорид – маркировка ПВХ или цифра 3; другой пластик – маркировка 7; а также – пластиковый лом, обертки от конфет, трубочки, зубные щетки, предметы содержащие бумагу, металл, загрязненные жиром предметы.\",\n",
        "                    \"Сухая фракция\": \"Выбрасываем: металл (металлические банки и крышечки из-под напитков, консервов, косметики, другие предметы из металла, очищенные от остатков грязи и пищи). Не выбрасываем: пищевые отходы, одноразовую посуду, вакуумную упаковку и упаковку типа “шуршик”, бумагу с остатками пищи и жира, пенопласт, резиновые изделия, одежду и текстиль.\"\n",
        "    }\n",
        "\n",
        "    if 'стекло' in s:\n",
        "      recycling = garbage_disposal.get('Стекло')\n",
        "    elif 'метал' in s or 'алюминий' in s or 'сталь' in s :\n",
        "      recycling = garbage_disposal.get('Сухая фракция')\n",
        "    elif 'картон' in s or 'пакет' in s:\n",
        "      recycling = garbage_disposal.get('Бумага')\n",
        "    else:\n",
        "      recycling = garbage_disposal.get('Пластик')\n",
        "\n",
        "    json[\"recycling\"] = recycling\n",
        "    return json"
      ],
      "id": "artistic-handbook",
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-iDTF9rvAsB9",
        "outputId": "30d9bbcc-d355-4c06-b436-a1075bfe213f"
      },
      "source": [
        "runn(4820051240233)"
      ],
      "id": "-iDTF9rvAsB9",
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "list index out of range\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Componenets_vs_rating': [(1, 'В Википедии нет статьи с таким названием. ')],\n",
              " 'Negative': 0.0,\n",
              " 'Positive': 1.0,\n",
              " 'barcode': 4820051240233,\n",
              " 'calories': 0,\n",
              " 'carbohydrates': 0,\n",
              " 'components': 'Вода минеральная',\n",
              " 'fats': 0,\n",
              " 'img': 'https://icf.listex.info/300x200/ed6393be-036a-32e2-1ecb-88507c6bc126.png',\n",
              " 'is_gmo': 'НЕТ',\n",
              " 'is_organic': 'НЕТ',\n",
              " 'is_vegan': 'ДА',\n",
              " 'is_vegetarian': 'ДА',\n",
              " 'mass': 0.0,\n",
              " 'name': 'Вода минеральная негазированная Карпатська Джерельна п/бут 0.5л.',\n",
              " 'package': 0,\n",
              " 'package2': 'ПОЛИЭТИЛЕНТЕРЕФТАЛАТ (ПЭТ/ПЭТФ), БУТЫЛКА {BOT}',\n",
              " 'proteins': 0,\n",
              " 'recycling': 'Выбрасываем: тару и упаковку – если видите на упаковке цифру 1 или маркировки PET, PETE; полиэтилен высокой и низкой плотности – маркировка HDPE, LDPE, или цифры 2 или 4; полипропилен в виде пленки, флаконов или контейнеров, полиэтилен в виде пленки – маркировка РР, или цифра 5, полистирена, полистирол – маркировка 6; упаковка tetra pak и pure pak. Не выбрасываем: цветные непрозрачные бутылки РЕТ черного, белого и желтого цветов; поливинилхлорид – маркировка ПВХ или цифра 3; другой пластик – маркировка 7; а также – пластиковый лом, обертки от конфет, трубочки, зубные щетки, предметы содержащие бумагу, металл, загрязненные жиром предметы.'}"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ZneVrL_C73p"
      },
      "source": [
        ""
      ],
      "id": "-ZneVrL_C73p"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UuE-fp7YC7zj"
      },
      "source": [
        ""
      ],
      "id": "UuE-fp7YC7zj"
    }
  ]
}